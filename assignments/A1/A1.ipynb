{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI4A-T0z5AU6"
      },
      "source": [
        "# Assignment 1\n",
        "You should submit the **UniversityNumber.ipynb** file and your final prediction file **UniversityNumber.test.txt** to moodle. Make sure your code does not use your local files and that the results are reproducible. Before submitting, please **1. clean all outputs and 2. run all cells in your notebook and keep all running logs** so that we can check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i62Pic0tacGe",
        "outputId": "e23f0ee0-6b97-46d4-f7b0-d84baf56bc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4 nltk==3.9.1 scikit-learn==1.6.1 gensim==4.3.3 setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ydSzHC6acGe",
        "outputId": "0648fc95-346e-4a21-d5f6-bdf92bd95345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-56c000555d47>:14: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ numpy version 1.26.4\n",
            "✓ nltk version 3.9.1\n",
            "✓ scikit-learn version 1.6.1\n",
            "✓ gensim version 4.3.3\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup and Validation\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Required package versions\n",
        "required_packages = {\n",
        "    'numpy': '1.26.4',\n",
        "    'nltk': '3.9.1',\n",
        "    'scikit-learn': '1.6.1',\n",
        "    'gensim': '4.3.3'\n",
        "}\n",
        "\n",
        "def validate_environment():\n",
        "    import pkg_resources\n",
        "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
        "    for package, min_version in required_packages.items():\n",
        "        if package not in installed:\n",
        "            print(f\"❌ {package} not found!\")\n",
        "            return False\n",
        "        if pkg_resources.parse_version(installed[package]) < pkg_resources.parse_version(min_version):\n",
        "            print(f\"❌ {package} version {installed[package]} is below minimum {min_version}\")\n",
        "            return False\n",
        "        print(f\"✓ {package} version {installed[package]}\")\n",
        "    return True\n",
        "\n",
        "assert validate_environment(), \"Please install required packages with correct versions\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEomoMzH5Nf6"
      },
      "source": [
        "# 1 $n$-gram Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YsSAtTqt7Q8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697bc51e-39b7-4da4-b688-b7e73cd2fa46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-28 16:36:22--  https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8441444 (8.0M) [text/plain]\n",
            "Saving to: ‘data/lm/train.txt’\n",
            "\n",
            "data/lm/train.txt   100%[===================>]   8.05M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-28 16:36:22 (59.2 MB/s) - ‘data/lm/train.txt’ saved [8441444/8441444]\n",
            "\n",
            "--2025-02-28 16:36:22--  https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1671618 (1.6M) [text/plain]\n",
            "Saving to: ‘data/lm/dev.txt’\n",
            "\n",
            "data/lm/dev.txt     100%[===================>]   1.59M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-28 16:36:23 (22.6 MB/s) - ‘data/lm/dev.txt’ saved [1671618/1671618]\n",
            "\n",
            "--2025-02-28 16:36:23--  https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1669761 (1.6M) [text/plain]\n",
            "Saving to: ‘data/lm/test.txt’\n",
            "\n",
            "data/lm/test.txt    100%[===================>]   1.59M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-02-28 16:36:23 (19.1 MB/s) - ‘data/lm/test.txt’ saved [1669761/1669761]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data/lm\n",
        "!wget -O data/lm/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/train.txt\n",
        "!wget -O data/lm/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/dev.txt\n",
        "!wget -O data/lm/test.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ElrINWW7oF7"
      },
      "source": [
        "## 1.1 Building vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECqpZn5NacGf"
      },
      "source": [
        "### Instructions:\n",
        "1. Implement a Vocabulary class that:\n",
        "   - Handles OOV words (tokens occurring < 3 times)\n",
        "   - Includes special tokens \\<UNK>, \\<START>, \\<END>\n",
        "   - Provides word2idx and idx2word mappings\n",
        "2. Expected vocabulary size: 24,067 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eawcuVV19kZm"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q-rNT_QL8Dvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40537eb7-612f-4b79-87b8-5bff18a3e7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 24067\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Building vocabulary\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<UNK>': 0, '<START>': 1, '<END>': 2}\n",
        "        self.idx2word = ['<UNK>', '<START>', '<END>']\n",
        "        self.word_counts = {}\n",
        "\n",
        "    def build_vocab(self, filepath: str, min_freq: int = 3) -> None:\n",
        "        \"\"\"Build vocabulary from training file\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to training file\n",
        "            min_freq: Minimum frequency threshold for words\n",
        "        \"\"\"\n",
        "        # TODO: Implement vocabulary building\n",
        "        # Read and tokenize the input file\n",
        "        content = ''\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f:\n",
        "                content += line.lower() + '\\n'\n",
        "\n",
        "        # Tokenize the text (whitespace-tokenized, as specified in the assignment)\n",
        "        nltk.download('punkt_tab')\n",
        "        words = nltk.word_tokenize(content)\n",
        "\n",
        "        # Count word frequencies\n",
        "        self.word_counts = Counter(words)\n",
        "        unk_count = 0\n",
        "        # Add words that meet frequency threshold to vocab\n",
        "        for word, count in self.word_counts.items():\n",
        "            if count >= min_freq and word not in self.word2idx:\n",
        "                idx = len(self.word2idx)\n",
        "                self.word2idx[word] = idx\n",
        "                self.idx2word.append(word)\n",
        "            else:\n",
        "                unk_count += count\n",
        "        self.word_counts['<UNK>'] = unk_count\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.word2idx)  # Subtract 2 to exclude <START> and <END> from the count\n",
        "\n",
        "    def get_id(self, word: str) -> int:\n",
        "        \"\"\"Get ID for word (returns UNK if not in vocab)\"\"\"\n",
        "        # TODO: Implement\n",
        "        return self.word2idx.get(word, self.word2idx['<UNK>'])\n",
        "\n",
        "    def get_word(self, idx: int) -> str:\n",
        "        \"\"\"Get word for ID\"\"\"\n",
        "        # TODO: Implement\n",
        "        return self.idx2word[idx]\n",
        "\n",
        "# Test vocabulary\n",
        "vocab = Vocabulary()\n",
        "vocab.build_vocab('data/lm/train.txt')\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "assert len(vocab) == 24067, \"Vocabulary size should be 24,067\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7oBATsX8uHb"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU6VpAkS9odh"
      },
      "source": [
        "Discuss the number of parameters in n-gram models here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of parameters in n-gram models here is $V^n$, where $V$ is the size of the vocabulary and $n$ is the number of words in the n-gram. In this case, the number of parameters is $24067^n$.\n",
        "\n",
        "The parameters are typically represented as conditional probabilities of the form:\n",
        "$$ P(w_n | w_{n-1}, w_{n-2}, ..., w_{1}) $$\n",
        "\n",
        "where $w_i$ is the $i$-th word in the n-gram. For each word $w_m$, there are $(n-1)$ words that precede it, and each of these words can be any of the $V$ words in the vocabulary. Therefore, there are $V^(n-1)$ possible combinations of the preceding words. Then, there are $V$ possible values for the word $w_m$. Therefore, there are $V\\times V^{n-1}=V^n$ possible parameters in the n-gram model."
      ],
      "metadata": {
        "id": "UyQoR1Tpfa2g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2BGUig8TqH"
      },
      "source": [
        "## 1.2 $n$-gram Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KljPWkGQacGg"
      },
      "source": [
        "### Instructions:\n",
        "1. Implement an n-gram language model that:\n",
        "   - Counts n-grams from training data\n",
        "   - Computes probabilities\n",
        "   - Calculates perplexity\n",
        "2. Test with both unigram and bigram models\n",
        "3. Report perplexity on train and dev sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyANMPe9ad_"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACSfNZGE8Yw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1bab37-6d1c-46b0-f10f-f8c6c9f37a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity on dev (bigram): 4.85\n",
            "Perplexity on train (bigram): 20.26\n",
            "Perplexity on dev (unigram): 109.23\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "\n",
        "class LanguageModel:\n",
        "    def __init__(self, vocab: Vocabulary, n: int):\n",
        "        \"\"\"Initialize n-gram language model\n",
        "\n",
        "        Args:\n",
        "            vocab: Vocabulary object\n",
        "            n: Order of n-gram model\n",
        "        \"\"\"\n",
        "        self.vocab = vocab\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "        self.context_counts = defaultdict(int)\n",
        "\n",
        "    def get_ngrams(self, tokens: List[str], n: int) -> List[Tuple[str]]:\n",
        "        \"\"\"Extract n-grams from token sequence\"\"\"\n",
        "        # TODO: Implement n-gram extraction\n",
        "        ngrams = []\n",
        "        # Slide over the token list to generate n-grams\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            ngram = tuple(tokens[i:i+n])\n",
        "            ngrams.append(ngram)\n",
        "        return ngrams\n",
        "\n",
        "    def train(self, filepath: str) -> None:\n",
        "        \"\"\"Train n-gram language model\"\"\"\n",
        "        # TODO: Implement training\n",
        "        with open(filepath, 'r') as f:\n",
        "            text = f.read()\n",
        "\n",
        "        sentences = text.splitlines()\n",
        "        for sentence in sentences:\n",
        "            words = sentence.split()\n",
        "            words = [word.lower() for word in words]\n",
        "            # Convert words to their corresponding ids using word2idx\n",
        "            words = [self.vocab.get_id(word) for word in words]\n",
        "            ngrams = self.get_ngrams(words, self.n)\n",
        "            for ngram in ngrams:\n",
        "                self.ngram_counts[ngram] += 1\n",
        "                context = ngram[:-1]  # Context is the first n-1 words\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "    def get_prob(self, word: str, context: Tuple[int]) -> float:\n",
        "        \"\"\"Get probability of word given context\"\"\"\n",
        "        word_id = self.vocab.get_id(word)\n",
        "        context_count = self.context_counts[context]\n",
        "        ngram_count = self.ngram_counts[context + (word_id,)]\n",
        "        if self.n == 1:  # Unigram case\n",
        "            return ngram_count / sum(self.ngram_counts.values())\n",
        "\n",
        "        # For bigram or trigram, apply smoothing and probability calculation\n",
        "        prob = ngram_count / context_count\n",
        "        if prob == 0:\n",
        "            return 1 / len(self.vocab)+context_count  # Smoothing (add-one)\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, filepath: str) -> float:\n",
        "        \"\"\"Calculate perplexity on given text\"\"\"\n",
        "        total_log_prob = 0\n",
        "        total_words = 0\n",
        "        with open(filepath, 'r') as f:\n",
        "            text = f.read()\n",
        "\n",
        "        sentences = text.splitlines()\n",
        "        for sentence in sentences:\n",
        "            total_words += len(sentence.split())\n",
        "            words = sentence.split()\n",
        "            words = [word.lower() for word in words]\n",
        "            # Convert words to their corresponding ids using word2idx\n",
        "            words = [self.vocab.get_id(word) for word in words]\n",
        "            ngrams = self.get_ngrams(words, self.n)\n",
        "            for ngram in ngrams:\n",
        "                context = ngram[:-1]\n",
        "                word_id = ngram[-1]\n",
        "                prob = self.get_prob(self.vocab.get_word(word_id), context)\n",
        "                #if prob == 0:\n",
        "                #    print(f\"Zero probability for {self.vocab.get_word(word_id)} given context {context}\")\n",
        "                total_log_prob += np.log(prob)\n",
        "\n",
        "        l = total_log_prob / total_words\n",
        "        perplexity = 2 ** -l\n",
        "        return perplexity\n",
        "\n",
        "# Test language model\n",
        "lm_2 = LanguageModel(vocab, n=2)\n",
        "lm_2.train('data/lm/train.txt')\n",
        "dev_perplexity = lm_2.perplexity('data/lm/dev.txt')\n",
        "print(f\"Perplexity on dev (bigram): {dev_perplexity:.2f}\")\n",
        "assert dev_perplexity > 0, \"Perplexity should be positive\"\n",
        "train_perplexity_2 = lm_2.perplexity('data/lm/train.txt')\n",
        "print(f\"Perplexity on train (bigram): {train_perplexity_2:.2f}\")\n",
        "\n",
        "lm_1 = LanguageModel(vocab, n=1)\n",
        "lm_1.train('data/lm/train.txt')\n",
        "dev_perplexity_1 = lm_1.perplexity('data/lm/dev.txt')\n",
        "print(f\"Perplexity on dev (unigram): {dev_perplexity_1:.2f}\")\n",
        "train_perplexity_1 = lm_1.perplexity('data/lm/train.txt')\n",
        "print(f\"Perplexity on train (unigram): {train_perplexity_1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWC56a19TbY"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM4gcgL--Ylh"
      },
      "source": [
        "Compare unigram and bigram model performance here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuLL8CH1Ua-3"
      },
      "source": [
        "## 1.3 Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7mWQhaCUixZ"
      },
      "source": [
        "### 1.3.1 Add-one (Laplace) smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbbHxLDmVrz6"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93_yLu9dVr0C"
      },
      "outputs": [],
      "source": [
        "class AddOneLanguageModel(LanguageModel):\n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get smoothed probability using add-one smoothing\"\"\"\n",
        "        # TODO: Implement add-one smoothing\n",
        "        pass\n",
        "\n",
        "# Test add-one smoothing\n",
        "add_one_lm = AddOneLanguageModel(vocab, n=2)\n",
        "add_one_lm.train('data/lm/train.txt')\n",
        "print(f\"Add-one perplexity on dev: {add_one_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y1WOQtsVr0D"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTknh9pRVr0D"
      },
      "source": [
        "Analyze how add-one smoothing affects the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTC0qJE8VVha"
      },
      "source": [
        "#### 1.3.2 Add-k smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNSonelAacGg"
      },
      "source": [
        "### Instructions:\n",
        "1. Implement add-k smoothing with configurable k\n",
        "2. Try k values: 0.1, 0.5, 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3itGMOOVuNg"
      },
      "source": [
        "##### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhcuJWo7VuNg"
      },
      "outputs": [],
      "source": [
        "class AddKLanguageModel(LanguageModel):\n",
        "    def __init__(self, vocab: Vocabulary, n: int, k: float):\n",
        "        super().__init__(vocab, n)\n",
        "        self.k = k\n",
        "\n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get smoothed probability using add-k smoothing\"\"\"\n",
        "        # TODO: Implement add-k smoothing\n",
        "        pass\n",
        "\n",
        "# Test add-k smoothing with different k values\n",
        "k_values = [0.1, 0.5, 1.0]\n",
        "for k in k_values:\n",
        "    add_k_lm = AddKLanguageModel(vocab, n=2, k=k)\n",
        "    add_k_lm.train('data/lm/train.txt')\n",
        "    print(f\"Add-{k} perplexity on dev: {add_k_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzpU_p6CVuNg"
      },
      "source": [
        "##### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIOUpNXYVuNh"
      },
      "source": [
        "Compare performance with different k values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJFWxsN-Uj0Y"
      },
      "source": [
        "### 1.3.3 Linear Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STtPYz-HacGg"
      },
      "source": [
        "### Instructions:\n",
        "1. Implement linear interpolation of unigram, bigram, and trigram models\n",
        "2. Initial lambdas: [0.1, 0.3, 0.6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk11EpboWVCH"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4N_XuN6WVCQ"
      },
      "outputs": [],
      "source": [
        "class InterpolatedLanguageModel:\n",
        "    def __init__(self, vocab: Vocabulary, lambdas: List[float]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab: Vocabulary object\n",
        "            lambdas: List of interpolation weights (should sum to 1)\n",
        "        \"\"\"\n",
        "        assert abs(sum(lambdas) - 1.0) < 1e-6, \"Lambdas must sum to 1\"\n",
        "        self.vocab = vocab\n",
        "        self.lambdas = lambdas\n",
        "        self.models = [LanguageModel(vocab, n=i+1) for i in range(len(lambdas))]\n",
        "\n",
        "    def train(self, filepath: str) -> None:\n",
        "        \"\"\"Train all n-gram models\"\"\"\n",
        "        for model in self.models:\n",
        "            model.train(filepath)\n",
        "\n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get interpolated probability\"\"\"\n",
        "        # TODO: Implement interpolated probability\n",
        "        pass\n",
        "\n",
        "    def perplexity(self, filepath: str) -> float:\n",
        "        \"\"\"Calculate perplexity using interpolated probabilities\"\"\"\n",
        "        # TODO: Implement perplexity calculation\n",
        "        pass\n",
        "\n",
        "# Test interpolated model\n",
        "lambdas = [0.1, 0.3, 0.6]  # Example weights for unigram, bigram, trigram\n",
        "interpolated_lm = InterpolatedLanguageModel(vocab, lambdas)\n",
        "interpolated_lm.train('data/lm/train.txt')\n",
        "print(f\"Interpolated perplexity on dev: {interpolated_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8v2P36WVCQ"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGkf6IV0WVCQ"
      },
      "source": [
        "Analyze the effectiveness of interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvgTZcNFVato"
      },
      "source": [
        "##### 1.3.4 Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnXu98hWcfu"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKo4ZLASWcfu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alFOf5GZacGh"
      },
      "source": [
        "# 2 Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxebkFhgacGj"
      },
      "outputs": [],
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each lengh 50\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "    print(\"Loaded vocab size %i\" % len(list(wv_from_bin.index_to_key)))\n",
        "    return wv_from_bin\n",
        "\n",
        "wv_from_bin = load_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk6i0OuNacGj"
      },
      "source": [
        "## 2.1 Find most similar word\n",
        "### Instructions:\n",
        "1. Implement function to find similar words using cosine similarity\n",
        "2. Expected similarity scores should be between 0 and 1\n",
        "3. Return top 3 similar words for each query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9BBmgW8acGj"
      },
      "outputs": [],
      "source": [
        "def find_most_similar(word: str, wv_from_bin) -> List[Tuple[str, float]]:\n",
        "    \"\"\"Find most similar words using cosine similarity\n",
        "\n",
        "    Args:\n",
        "        word: Query word\n",
        "        wv_from_bin: Loaded word vectors\n",
        "\n",
        "    Returns:\n",
        "        List of (word, similarity) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement similarity search\n",
        "    pass\n",
        "\n",
        "test_words = [\n",
        "    'ubiquitous',\n",
        "    'serendipity',\n",
        "    'melancholy',\n",
        "    'paradox',\n",
        "    'ethereal',\n",
        "    'cacophony'\n",
        "]\n",
        "for word in test_words:\n",
        "    similar_words = find_most_similar(word, wv_from_bin)\n",
        "    print(f\"\\nMost similar to '{word}':\")\n",
        "    for similar_word, similarity in similar_words:\n",
        "        print(f\"{similar_word}: {similarity:.3f}\")\n",
        "        assert 0 <= similarity <= 1, f\"Invalid similarity score: {similarity}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVJg_8WLacGj"
      },
      "source": [
        "## 2.2 Finding Analogies\n",
        "Use vector addition and subtraction to compute target vectors for the analogies below. After computing each target vector, find the top three candidates by cosine similarity. Report the candidates and their similarities to the target vector.\n",
        "\n",
        "- dog : puppy :: cat : ?:\n",
        "- speak : speaker :: sing : ?:\n",
        "- France : French :: England : ?:\n",
        "- France : wine :: England : ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBRDqDnvacGk"
      },
      "outputs": [],
      "source": [
        "def find_analogy(a: str, b: str, c: str, wv_from_bin) -> List[Tuple[str, float]]:\n",
        "    \"\"\"Find word analogies using vector arithmetic\n",
        "\n",
        "    Args:\n",
        "        a, b, c: Words for analogy a:b :: c:?\n",
        "        wv_from_bin: Loaded word vectors\n",
        "\n",
        "    Returns:\n",
        "        List of (word, similarity) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement analogy finding\n",
        "    pass\n",
        "\n",
        "# Test analogies\n",
        "analogies = [\n",
        "    ('king', 'queen', 'man'),\n",
        "    ('paris', 'france', 'rome'),\n",
        "    ('france', 'french', 'germany'),\n",
        "    ('london', 'england', 'paris'),\n",
        "    ('cat', 'kitten', 'dog'),\n",
        "    ('rich', 'poor', 'strong')\n",
        "]\n",
        "for a, b, c in analogies:\n",
        "    print(f\"\\nAnalogy: {a}:{b} :: {c}:?\")\n",
        "    results = find_analogy(a, b, c, wv_from_bin)\n",
        "    for word, similarity in results:\n",
        "        print(f\"{word}: {similarity:.3f}\")\n",
        "        assert 0 <= similarity <= 1, f\"Invalid similarity score: {similarity}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFjAGdNQacGk"
      },
      "source": [
        "# 3 Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-QIZXJ8acGk"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/classification\n",
        "!wget -O data/classification/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/train.txt\n",
        "!wget -O data/classification/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/dev.txt\n",
        "!wget -O data/classification/test-blind.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/test-blind.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMXx9i0MacGk"
      },
      "source": [
        "## 3.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEDKg6dZacGk"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "def load_data(filepath: str) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"Load text and labels from file\"\"\"\n",
        "    texts, labels = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split('\\t')\n",
        "            texts.append(text)\n",
        "            labels.append(int(label))\n",
        "    return texts, labels\n",
        "\n",
        "class SentimentClassifier:\n",
        "    def __init__(self, feature_type: str = 'unigram'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_type: One of 'unigram', 'bigram', or 'glove'\n",
        "        \"\"\"\n",
        "        self.feature_type = feature_type\n",
        "        self.vectorizer = None\n",
        "        self.classifier = LogisticRegression(random_state=42)\n",
        "\n",
        "    def extract_features(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Extract features based on feature_type\"\"\"\n",
        "        if self.feature_type == 'unigram':\n",
        "            # TODO: Implement unigram feature extraction\n",
        "            pass\n",
        "        elif self.feature_type == 'bigram':\n",
        "            # TODO: Implement bigram feature extraction\n",
        "            pass\n",
        "        elif self.feature_type == 'glove':\n",
        "            # TODO: Implement glove feature extraction\n",
        "            # Average word vectors for each text\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid feature type: {self.feature_type}\")\n",
        "\n",
        "    def train(self, train_texts: List[str], train_labels: List[int]) -> None:\n",
        "        \"\"\"Train sentiment classifier\"\"\"\n",
        "        # TODO: Implement training\n",
        "        pass\n",
        "\n",
        "    def predict(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict sentiment labels\"\"\"\n",
        "        # TODO: Implement prediction\n",
        "        pass\n",
        "\n",
        "    def evaluate(self, texts: List[str], labels: List[int]) -> Dict:\n",
        "        \"\"\"Evaluate classifier performance\"\"\"\n",
        "        predictions = self.predict(texts)\n",
        "        return classification_report(labels, predictions, output_dict=True)\n",
        "\n",
        "# Train and evaluate models with different features\n",
        "train_texts, train_labels = load_data('data/classification/train.txt')\n",
        "dev_texts, dev_labels = load_data('data/classification/dev.txt')\n",
        "\n",
        "results = {}\n",
        "for feature_type in ['unigram', 'bigram', 'glove']:\n",
        "    classifier = SentimentClassifier(feature_type)\n",
        "    classifier.train(train_texts, train_labels)\n",
        "    results[feature_type] = classifier.evaluate(dev_texts, dev_labels)\n",
        "\n",
        "# Print results\n",
        "for feature_type, metrics in results.items():\n",
        "    print(f\"\\n{feature_type.upper()} Results:\")\n",
        "    print(f\"Precision: {metrics['weighted avg']['precision']:.3f}\")\n",
        "    print(f\"Recall: {metrics['weighted avg']['recall']:.3f}\")\n",
        "    print(f\"F1-score: {metrics['weighted avg']['f1-score']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTfKiBPCacGk"
      },
      "source": [
        "Compare the performance of three types of features on dev set. Report the weighted average precision, recall and F1-score for each feature set.\n",
        "\n",
        "| Feature | precision | recall | F1-score |\n",
        "| ----------- | --------- | ------ | -------- |\n",
        "| unigram     |           |        |          |\n",
        "| bigram      |           |        |          |\n",
        "| GloVe       |           |        |          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJlZC1gHacGk"
      },
      "source": [
        "## 3.2 Better Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om622NXJacGk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}